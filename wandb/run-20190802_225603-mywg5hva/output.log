Using CUDA for RNN layers
WARNING: Logging before flag parsing goes to stderr.
W0802 22:56:04.491711 140688115259200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W0802 22:56:04.493736 140688115259200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0802 22:56:04.497531 140688115259200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0802 22:56:04.513462 140688115259200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

Traceback (most recent call last):
  File "train.py", line 74, in <module>
    model.add(Bidirectional(LSTM(config.hidden_dims)))
  File "/usr/local/lib/python3.6/dist-packages/wandb/wandb_config.py", line 184, in __getattr__
    return self.__getitem__(key)
  File "/usr/local/lib/python3.6/dist-packages/wandb/wandb_config.py", line 174, in __getitem__
    return self._items[key]
KeyError: 'hidden_dims'
